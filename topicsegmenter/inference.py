import torch
import re
import os
import inspect
from typing import List
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from src.utils import normalize_text

class NewsSegmenter:
    def __init__(self, model_path: str, base_model_name: str = "DeepPavlov/rubert-base-cased"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"Loading weights from: {model_path}")
        
        # ЛЕЧИМ ОШИБКУ MISTRAL:
        # Грузим чистый токенизатор из интернета, игнорируя конфиги в папке
        # self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        
        # Грузим веса модели
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        self.model.to(self.device)
        self.model.eval()
        self._accepts_token_type_ids = self._model_accepts_token_type_ids(self.model)

    @staticmethod
    def _model_accepts_token_type_ids(model) -> bool:
        try:
            return "token_type_ids" in inspect.signature(model.forward).parameters
        except (TypeError, ValueError):
            return False

    def _normalize(self, text: str) -> str:
        # Должно СТРОГО совпадать с тем, что в ASRAugmentor.apply
        return normalize_text(text)

    def _predict_batch(self, pairs: List[tuple]) -> List[float]:
        """Пакетное предсказание вероятностей."""
        if not pairs: return []
        
        batch_size = 32
        all_probs = []
        
        for i in range(0, len(pairs), batch_size):
            batch = pairs[i:i+batch_size]
            lefts = [self._normalize(p[0]) for p in batch]
            rights = [self._normalize(p[1]) for p in batch]
            
            inputs = self.tokenizer(
                lefts, rights,
                add_special_tokens=True, max_length=128, # Совпадает с новым Config.max_len
                padding="max_length", truncation=True, return_tensors="pt"
            )

            if not self._accepts_token_type_ids and "token_type_ids" in inputs:
                inputs.pop("token_type_ids")

            inputs = inputs.to(self.device)
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                probs = torch.softmax(outputs.logits, dim=1)
                all_probs.extend(probs[:, 1].cpu().tolist())
                
        return all_probs

    def _find_local_peak(self, words: List[str], center_idx: int, radius: int = 10) -> (int, float):
        """Сканирует область вокруг center_idx, ищет максимум вероятности."""
        start = max(1, center_idx - radius)
        end = min(len(words) - 1, center_idx + radius)
        
        candidates = []
        indices = []
        for i in range(start, end + 1):
            ctx_left = " ".join(words[max(0, i-50):i])
            ctx_right = " ".join(words[i:min(len(words), i+50)])
            candidates.append((ctx_left, ctx_right))
            indices.append(i)
            
        probs = self._predict_batch(candidates)
        
        best_prob = -1.0
        best_idx = center_idx
        for idx, prob in zip(indices, probs):
            if prob > best_prob:
                best_prob = prob
                best_idx = idx
        return best_idx, best_prob

    def segment_text(self, text: str) -> List[str]:
        words = text.split()
        print(f"Processing {len(words)} words...")
        
        # Настройки
        MIN_LEN = 10  # Увеличиваем минимальную длину новости
        CONFIRM_THR = 0.8  # Немного поднимаем порог
        
        # 1. Сбор всех точек (STEP=1)
        scan_indices = list(range(MIN_LEN, len(words) - MIN_LEN))
        if not scan_indices:
            return [text]

        candidates = []
        for i in scan_indices:
            # Используем 50 слов, чтобы влезло в max_len=128
            ctx_left = " ".join(words[max(0, i-50):i])
            ctx_right = " ".join(words[i:min(len(words), i+50)])
            candidates.append((ctx_left, ctx_right))
            
        # 2. Массовое предсказание (Batch Inference)
        print(f"Running full scan on {len(candidates)} points...")
        probs = self._predict_batch(candidates)
        
        # 3. Поиск пиков
        split_indices = [0]
        i = 0
        while i < len(probs):
            prob = probs[i]
            idx = scan_indices[i]
            
            # Проверяем, является ли это локальным пиком
            is_peak = True
            if i > 0 and probs[i-1] >= prob: is_peak = False
            if i < len(probs) - 1 and probs[i+1] > prob: is_peak = False
            
            if is_peak and prob > CONFIRM_THR:
                # Проверка на минимальную длину от предыдущего разрыва
                if idx - split_indices[-1] >= MIN_LEN:
                    print(f"    >>> CUT at {idx} ('{words[idx-1]}'), prob={prob:.4f}")
                    split_indices.append(idx)
                    
                    # Пропускаем MIN_LEN слов
                    while i < len(scan_indices) and scan_indices[i] < idx + MIN_LEN:
                        i += 1
                    continue
            
            i += 1

        split_indices.append(len(words))
        
        # Сборка
        segments = []
        for k in range(len(split_indices) - 1):
            segments.append(" ".join(words[split_indices[k]:split_indices[k+1]]))
            
        return segments

if __name__ == "__main__":
    # Чтобы убрать ошибку Mistral навсегда, удалите старые конфиги
    checkpoint_dir = "./checkpoints/best_model"
    # for junk in ["tokenizer_config.json", "special_tokens_map.json", "tokenizer.json"]:
    #     p = os.path.join(checkpoint_dir, junk)
    #     if os.path.exists(p):
    #         os.remove(p)


    segmenter = NewsSegmenter(checkpoint_dir)

    long_text = (
        "сегодня в северном техническом университете представили прототип новой батареи для портативной электроники и дронов заявленная плотность энергии выше чем у предыдущих образцов и как бы это привлекло много студентов и инженеров мы работаем из лаборатории номер двенадцать здесь шум вытяжки и поэтому речь может пропадать руководитель проекта аллина жукова извините алина говорит что команда перешла на гибридный катод на основе никеля и марганца и добавила добавила что электролит использует солевой раствор с пониженой летучестью при комнатной температуре стенд показывает быстрое восстановлен е более семидесяти процентов зарядки за пятнадцать минут но это предварительные данные они подчёркивают что нужно ещё десять циклов тестов на деградацию компонетов в корридоре мы встретили аспиранта роман руднева он объясняет что в прототипе есть тонкая мембрана идущая из композита и что её производство может быть дорогим пока учёные ищут локального подрядчика в пресс релизе который раздавали на входе было написано латиницей battery proto v3 и там же ошибка в фамилии авторов жуково без а теперь о безопасности представители лаборатории подчёркнули что ячейки не содержат кобальта и это снижает экологический след но всё равно требуется утилизац по правилам эээ ведущий спрашивает а как насчёт совместимости с существующими устройствами ответ такой форм фактор будет повторять популярные стандарты 18650 и pouch варианты а также планируют модульный блок для квадрокоптеров организаторы показали небольшой дрон который поднялся в воздух на три минуты это не рекорд но демонстрация стабильности напряжения без провалов и перегрева температурный профиль снимали тепловизором график выглядит ровно между двадцать восемь и тридцать два градуса в соседнем кабинете обсуждали технологию покрытия токосъёмных пластин там инженер петрович простите нет точного имени он говорит что порошок поставляют из ростех хим но возможно скоро переключатся на местного дилера из колпино тут в репортаже всплыла заминка камера ушла в расфокус и мы на секунду потеряли картинку зато слышали как студенты хлопают и кричат ура ура вот такие эмоции презентация шла почти час на вопросы об интеллектуальной собственности жукова ответила что патент уже подан и ожидается публикация заявки зимой а пока партнёрам дают доступ под nda давайте добавим комментарий независимого специалиста из инж центра волна он говорит сказал что показатель плотности энергии выглядит перспективно но важно проверить поведение на морозе и в циклах быстрая зарядка иногда вызывает литиевое платирование цитирую аккуратно не спешите бежать в магазин конец цитаты в целом университет объявил о пилотной линии к следующей весне если финансирование подтвердят ректор отметил что переговоры с индустриальными партнёрами из питерского тех парка идут в рабочем режиме и есть шанс получить грант городского уровня мы остаёмся на площадке и будем следить за испытаниями итог дня таков прототип есть цифры есть впереди валидац тестов и много работы но настроение бодрое студенты уже сделали фото и выкладывают live истории в сети "
        "на финансовых рынках сегодня заметно оживление хотя волатильност осталась высокой аналитики центра орбита говорять что инвесторы реагируют на квартальные отчеты и на ожидания по ставкам крупнейших центробанков глобально индекс мби растёт на один и две десятых процента по предварительным подсчётам а технологический сектор лидирует по сохраненню спроса эээ вот наш обозреватель никита раев он на связи из студии он говорит что крупные игроки перекладываются из защитных активов в акции роста и это видно по оборотам в бумагах полупроводников и облачных сервисов при этом по словам по словам экспертов любые намёки на замедление прибыли могут быстро изменить настроение у нас есть комментарий с площадки международной фондовой биржи трейдер представился как сергей х не расслышал фамилию извините он сказал что роботы включились раньше чем ожидали и утром был всплеск алгоритмных покупок а затем консолидация к полудню курс некоторых валют распилился извините распилился это он так сказал там был фоновый шум и просто не разобрал я думаю речь про распил по диапазону в коридоре один тридцать один тридцать два к доллару кстати на сырьевом рынке нефть показала умеренный рост примерно на ноль точка восемь процента металллы разнонаправлено золото плюс маленький процент серебро около нуля а медь снижается что может быть связано с ожиданием данных по строй сектору здесь мы делаем ремарку что в прошлом месяце участники рынка переоценили шансы на скорое смягчение политики и сейчас риторика стала осторожнеи многие говорят дождёмся протокола комитета и потом уже решим добавили что значительная часть ралли вызвана закрытием коротких позиций отдельные бумаги растут на новостях о бай бек программах вот например крупный разработчик софта объявил о расширении обратного выкупа и рынок отреагировал всплеском объёмов но наш эксперт напоминает что байбек не равен росту выручки так что не стоит путать эти вещи эээ важный момент по облигациям доходности на длинном конце слегка снизились что даёт сектору недвижимости глоток воздуха однако риски остаются потому что рефинансирование торговых центров под вопросом мы слышим от управляющих что они закладывают стресс сценарии в модели оценки кэша и так по инфляции предварительный консенсус говорит про умеренное замедление в год к году но базовая составляюща может удивить и если она окажется упорной то реакция рынка будет резкой как говорят трейдеры флип сценарий здесь ещё что заметили участники азиатской сессии утром там главное движение прошло в технологических гигантах и на слухах о новых контрмерах регулятора по листингам некоторые издания упоминали площадку с неправильным названием нью йорк борд видимо опечатка да чтобы не вводить в заблуждение укажем это как ошибку редакции пока итоги дня выглядят зелеными но помните дисклеймер инвестиционные решения несут риски и это не рекомендац я мы продолжаем следить за динамикой если капитал потечёт обратно в облигации значит участники испугались очередных сюрпризов пока же у мониторов бодро мигают объёмы и алгоритмы балан сируют книгу заявок на этом всё к текущему часу услышымся позже"
    )

    results = segmenter.segment_text(long_text)
    
    print("\n" + "="*30)
    for i, seg in enumerate(results):
        print(f"NEWS {i+1}: {seg}")
    print("="*30)

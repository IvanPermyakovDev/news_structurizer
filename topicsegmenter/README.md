# Отчет по текущему решению Topic Segmenter

## 1) Задача и целевой сценарий

Цель проекта — находить границы между “новостями/темами” внутри длинного потока текста, похожего на результат распознавания речи (ASR): без пунктуации, с ошибками в словах, со сломанными границами предложений и возможными “склейками” фраз.

Практический формат задачи здесь сведен к бинарной проверке: “есть ли разрыв темы **в конкретной позиции** между левым и правым контекстом”.

Результат работы системы в инференсе — разбиение длинной строки на список сегментов (каждый сегмент соответствует одной теме/новости).

## 2) Общая идея решения

Решение построено вокруг модели семейства BERT, обученной как бинарный классификатор:

- На вход подаются две строки: `context_left` и `context_right`.
- Модель возвращает вероятность класса 1 — “между левым и правым контекстом проходит граница темы”.

Далее, для разметки “реального” длинного текста используется сканирование возможных границ по словам: для каждой позиции строятся левый и правый контекст, прогоняются через модель, после чего по локальным максимумам вероятности выбираются места разрезов.

## 3) Структура репозитория (важные файлы)

- `src/config.py` — все ключевые параметры (пути, гиперпараметры обучения, вероятности аугментаций, устройство).
- `src/dataset.py` — датасет для обучения/валидации, а также логика синтетического усложнения данных (mixing + jittering + текстовые аугментации).
- `src/augmentations.py` — “ASR-подобные” искажения текста.
- `src/utils.py` — фиксация seed и настройки детерминизма.
- `train.py` — обучение, логирование в TensorBoard, сохранение лучшей модели по F1.
- `inference.py` — сегментация длинного текста (поиск разрывов в потоке).
- `split_dataset.py` — разбиение исходного файла на `data/train.jsonl` и `data/val.jsonl`.

## 4) Формат данных и статистика

### 4.1. Формат одного примера

Каждый пример — это объект с тремя ключами:

- `context_left`: текст слева от предполагаемой границы
- `context_right`: текст справа от предполагаемой границы
- `label`: 1 если между ними реальный разрыв темы, иначе 0

Важно: в обучении датасет может “переопределять” место разреза и метку через jitter/mixing (см. раздел 5).

### 4.2. Наборы и размерности

По текущим файлам:

- `data/train.jsonl`: 11478 примеров (label 0: 6705, label 1: 4773)
- `data/val.jsonl`: 1276 примеров (label 0: 783, label 1: 493)
- `dataset.jsonl`: 12754 примеров (label 0: 7488, label 1: 5266)

Длины контекстов по словам (приближенно):

- Train: медиана около 22 слов слева и 22 слов справа; 90-й перцентиль около 37–38 слов; встречаются длинные хвосты до ~140–170 слов.

Модель при токенизации использует ограничение `max_len` (по умолчанию 128 токенов), поэтому фактически “видимый” контекст может быть меньше исходного текста по словам.

### 4.3. Примеры данных (без кода)

Пример с `label = 1` (разрыв темы):

- `context_left`: фрагмент про транспорт/инфраструктуру, заканчивающийся словами про безопасность и развитие
- `context_right`: фрагмент, который внезапно начинается с археологии (“в египте нашли древние папирусы…”)
- смысл: модель должна уверенно сработать, потому что “переход” резкий и тематически не связан

Пример с `label = 0` (нет разрыва):

- `context_left`: фрагмент про рынок аренды/цены и причины роста
- `context_right`: продолжение про условия сделки, города, сезонность
- смысл: это одна тема, разрез искусственный и не должен восприниматься как граница новостей

## 5) Подготовка данных в `SegmentationDataset`

В `src/dataset.py` при обучении применяется три уровня усложнения данных.

### 5.1. Synthetic Topic Mixing (смешивание тем)

С вероятностью `mix_prob` левый контекст берется из текущего примера, а правый — из другого случайного примера (как “чужое продолжение”).

Эффект:

- получается гарантированный тематический разрыв
- метка принудительно становится `label = 1`
- модель видит больше “контрастных” разрывов и учится не зависеть от конкретных шаблонов исходного датасета

Пример:

- слева: “сегодня в москве ожидается облачная погода…”
- справа: “сбербанк снизил ставки по ипотеке…”
- ожидаемая метка: разрыв есть (1), потому что темы не связаны

### 5.2. Jittering (сдвиг границы — hard negatives)

Если исходный пример имеет `label = 1`, то при обучении:

- с вероятностью `jitter_prob` граница сохраняется как есть (остается `label = 1`)
- иначе граница сдвигается на случайное число слов в диапазоне до `max_jitter_shift`, а метка становится `label = 0`

Зачем это нужно:

- модель должна не просто понимать “что где-то рядом есть разрыв”, а уметь **локализовать** его
- сдвинутые разрезы около реальной границы становятся сложными отрицательными примерами: контекст уже “подпорчен” соседней темой, но это еще не “правильная” позиция разреза

Пример (идея):

- истинная граница: …“матч завершился со счетом три два” | “министерство финансов предложило…”
- jitter-граница (на 2 слова правее): …“три два министерство” | “финансов предложило…”
- метка для jitter-границы: 0, потому что разрез поставлен неверно, несмотря на близость к реальной границе

Если исходный пример имеет `label = 0`, то при обучении разрез выбирается случайно внутри полного текста (не у самого края), чтобы получать разнообразные “обычные” отрицательные примеры.

### 5.3. Текстовые аугментации под ASR

С вероятностью `aug_prob` к каждому из контекстов независимо применяется пайплайн искажений из `src/augmentations.py`. Общая идея — сделать текст похожим на “грязный” ASR:

- приведение к нижнему регистру, выкидывание части пунктуации
- удаление/вставка/перестановка слов
- “склейка” коротких слов с последующими (типичная ошибка разбиения токенов)
- фонетические замены гласных и упрощения окончаний
- символьные ошибки, вырезание кусочков, случайное обрезание краев

Примеры возможных искажений (иллюстративно):

- “в москве прошел дождь” → “в маскве прашол дож”
- “в лесу” → “влесу”
- “кажется” → “кажеца”
- “команда сыграла очень хорошо” → “команда сыграла хорошо” (пропуск слова)

## 6) Модель и представление входа

### 6.1. Базовая модель

Используется `DeepPavlov/rubert-base-cased` как основа и головка бинарной классификации (2 класса).

### 6.2. Что именно классифицируется

Классифицируется не “текст целиком”, а **граница между двумя частями**. Вход формируется как пара последовательностей (левый и правый контекст), что позволяет модели сравнивать смысл и связность “до” и “после”.

### 6.3. Ограничение по длине

В токенизаторе выставлен `max_len = 128` с усечением. Это означает:

- длинные контексты “обрезаются”
- модель в большей степени опирается на локальные признаки вокруг предполагаемой границы, чем на весь исходный фрагмент

## 7) Обучение и оценка качества

В `train.py`:

- логирование ведется в `runs/experiment_v1` (TensorBoard)
- лучшая модель сохраняется в `checkpoints/best_model` по максимальному F1 на валидации
- метрики: Accuracy, Precision, Recall, F1 (binary)

Ключевые настройки по умолчанию из `src/config.py`:

- batch size: 64
- epochs: 100
- learning rate: 5e-5, weight decay: 0.01
- warmup: 200 шагов
- клиппинг градиента: 1.0

## 8) Инференс: как из вероятностей получаются сегменты

Класс `NewsSegmenter` в `inference.py` решает задачу “нарезки” так:

1) Текст разбивается на слова.
2) Дальше рассматриваются позиции между словами как кандидаты на границу.
3) Для кандидата строятся:
   - левый контекст: до позиции (с ограничением окна примерно до 50 слов)
   - правый контекст: после позиции (аналогично)
4) Модель оценивает вероятность разрыва.
5) По тексту идет грубый проход с шагом (по умолчанию 5 слов). Если вероятность превысила небольшой “триггер”:
   - запускается локальный поиск пика в окрестности (несколько слов вокруг)
6) Если найденный пик выше порога подтверждения, то граница фиксируется, и алгоритм перескакивает вперед, чтобы не резать слишком часто.

Параметры инференса (в текущем виде “зашиты” в `segment_text`):

- шаг грубого поиска: 5 слов
- порог “подозрения”: 0.05
- порог подтверждения: 0.8
- минимальная длина сегмента: 5 слов

### Пример ожидаемого результата сегментации (без кода)

Вход (единый поток слов, 3 темы):

1) “сегодня в москве ожидается облачная погода … ветер умеренный”
2) “хоккейный клуб спартак одержал победу … решающую шайбу забросили …”
3) “в китае успешно прошел запуск новой ракеты … вывела на орбиту спутник связи …”

Выход (3 сегмента):

- Сегмент 1: весь блок про погоду
- Сегмент 2: весь блок про хоккей
- Сегмент 3: весь блок про запуск ракеты

## 9) Результаты 

F1: 0.9085 | P: 0.9308 | R: 0.8874